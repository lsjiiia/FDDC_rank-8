{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import boxcox,norm,skew\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造loss函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 股票代码与行业和市值的映射(2018-5-31)\n",
    "df_map=pd.read_csv('../data/maket_value_type_map.csv').set_index(\"TICKER_SYMBOL\")\n",
    "\n",
    "###股票代码/日期与营业收入的映射\n",
    "dfs_revenue=pd.read_excel(\"../data/[Add June July] FDDC_financial_data_20180711/[New] Financial Data_20180711/Income Statement.xls\",sheet_name=[0,1,2,3],parse_date='END_DATE')\n",
    "dfs_revenue=pd.concat(dfs_revenue,axis=0)\n",
    "df_revenue=dfs_revenue.sort_values('PUBLISH_DATE').groupby(\n",
    "    [dfs_revenue['TICKER_SYMBOL'],dfs_revenue['END_DATE']]).apply(lambda x: x.iloc[-1])[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(date,ticker,revenue_pred):\n",
    "    basic=min(abs(revenue_pred/df_revenue.loc[ticker,date]-1),0.8)\n",
    "    alpha=np.log(max(df_map.loc[ticker][\"MARKET_VALUE\"],2))/np.log(2)\n",
    "    \n",
    "    return basic*alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入数据并进行异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"../data/train_all_na_done.csv\")\n",
    "df_test=pd.read_csv(\"../data/test_all_na_done.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train=df_train[df_train[\"END_DATE\"]!=\"2011-06-30\"]\n",
    "df_train=df_train[df_train[\"label\"]>5e5]\n",
    "df_all=pd.concat([df_train,df_test],axis=0).reset_index().drop(\"index\",axis=1)\n",
    "df_all[\"label\"]=df_all[\"label\"].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"recommend1\",\"recommend2\",\"recommend3\"]:\n",
    "    temp=[]\n",
    "    for i in df_all[col]:\n",
    "        if i<=1:\n",
    "            temp.append(0)\n",
    "        else:\n",
    "            temp.append(np.log(i))\n",
    "    df_all[col]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm([\"recommend1\",\"recommend2\",\"recommend3\"]):\n",
    "    lower_limit=df_all[col].mean()-5*df_all[col].std()\n",
    "    upper_limit=df_all[col].mean()+5*df_all[col].std()\n",
    "    for i in range(df_all.shape[0]):\n",
    "        if df_all[col][i]>upper_limit:\n",
    "            df_all[col][i]=upper_limit\n",
    "        elif df_all[col][i]<lower_limit:\n",
    "            df_all[col][i]=lower_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分离训练数据和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_all.shape[0]==df_test.shape[0]+df_train.shape[0]\n",
    "df_train=df_all[df_all[\"label\"].notnull()]\n",
    "df_test=df_all[df_all[\"label\"].isnull()].drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加每个样本的权重列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20105/20105 [00:06<00:00, 3098.66it/s]\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for index in tqdm(df_train.index):\n",
    "    market_value=df_map.loc[df_train.loc[index,\"TICKER_SYMBOL\"]][\"MARKET_VALUE\"]\n",
    "    temp.append(np.log(max(market_value,2)))\n",
    "df_train[\"coef\"]=temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算只用,recommend1做计算loss,作为baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t_loss=0\n",
    "# for i in df_train.index[-1000:]:\n",
    "#     date=df_train.loc[i,\"END_DATE\"]\n",
    "#     ticker=df_train.loc[i,\"TICKER_SYMBOL\"].astype(int)\n",
    "#     val_pred=df_train.loc[i,\"recommend1\"]\n",
    "#     loss=cal_loss(date,ticker,np.exp(val_pred))\n",
    "#     if np.isnan(loss):\n",
    "#         loss=0.753\n",
    "#     t_loss=t_loss+loss\n",
    "# print(t_loss)\n",
    "# print(t_loss/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.concat([pd.get_dummies(df_train.drop(\"END_DATE\",axis=1)),df_train[\"END_DATE\"]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 给每个样本加权重,可以通过控制每个样本出现次数的方式实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#choice_index=np.random.choice(df_train.shape[0]-1000,200000,p=df_train[\"coef\"][:-1000]/df_train[\"coef\"][:-1000].sum())\n",
    "choice_index=[]\n",
    "for i in df_train.index[:-1000]:\n",
    "    for j in range(int(np.round(df_train.loc[i,\"coef\"],0))):\n",
    "        choice_index.append(i)\n",
    "                   \n",
    "df_train_new=df_train.loc[choice_index]\n",
    "\n",
    "df_test=pd.concat([pd.get_dummies(df_test.drop([\"END_DATE\",\"TICKER_SYMBOL\"],axis=1)),df_test[\"TICKER_SYMBOL\"]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "# from sklearn.linear_model import LinearRegression,Lasso\n",
    "\n",
    "# reg_xgb=xgb.XGBRegressor(colsample_bytree=0.725,gamma=0.57,\n",
    "#                              learning_rate=0.0083, max_depth=9,\n",
    "#                              min_child_weight=0.96, n_estimators=1478,\n",
    "#                              reg_alpha=0.38, reg_lambda=0.3,\n",
    "#                              subsample=0.84, silent=1,\n",
    "#                              random_state =8, nthread = 4)\n",
    "\n",
    "# reg_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=54,\n",
    "#                               learning_rate=0.02, n_estimators=820,\n",
    "#                               max_bin = 455, bagging_fraction = 0.69,\n",
    "#                               bagging_freq = 50, feature_fraction = 0.636,\n",
    "#                               feature_fraction_seed=9, bagging_seed=9,\n",
    "#                               min_data_in_leaf =15, min_sum_hessian_in_leaf = 6)\n",
    "\n",
    "# model1=reg_xgb.fit(df_train_new.drop([\"END_DATE\",\"TICKER_SYMBOL\",\"label\",\"coef\"],axis=1),\n",
    "#                   df_train_new[\"label\"])\n",
    "\n",
    "# pred1=model1.predict(df_train.drop([\"END_DATE\",\"TICKER_SYMBOL\",\"label\",\"coef\"],axis=1)[-1000:])\n",
    "\n",
    "\n",
    "# model2=reg_lgb.fit(df_train_new.drop([\"END_DATE\",\"TICKER_SYMBOL\",\"label\",\"coef\"],axis=1),\n",
    "#                   df_train_new[\"label\"])\n",
    "\n",
    "# pred2=model2.predict(df_train.drop([\"END_DATE\",\"TICKER_SYMBOL\",\"label\",\"coef\"],axis=1)[-1000:])\n",
    "\n",
    "# for i in range(6):\n",
    "#     rate_lgb=0.1*i\n",
    "#     pred=rate_lgb*pred2+pred1*(1-rate_lgb)\n",
    "#     t_loss=0\n",
    "#     for j,i in enumerate(df_train.index[-1000:]):\n",
    "#         date=df_train.loc[i,\"END_DATE\"]\n",
    "#         ticker=df_train.loc[i,\"TICKER_SYMBOL\"].astype(int)\n",
    "#         val_pred=pred[j]\n",
    "\n",
    "#         loss=cal_loss(date,ticker,np.exp(val_pred))\n",
    "#         t_loss=t_loss+loss\n",
    "#     print(\"with rate_lgb: {0}, we get loss:{1}\".format(rate_lgb,t_loss))\n",
    "#     print(\"and the avg loss is:{}\\n\".format(t_loss/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87020, 133)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choice_index=np.random.choice(df_train.shape[0]-1000,200000,p=df_train[\"coef\"][:-1000]/df_train[\"coef\"][:-1000].sum())\n",
    "choice_index=[]\n",
    "for i in df_train.index:\n",
    "    for j in range(int(np.round(df_train.loc[i,\"coef\"],0))):\n",
    "        choice_index.append(i)\n",
    "                   \n",
    "df_train_all_new=df_train.loc[choice_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "\n",
    "reg_xgb=xgb.XGBRegressor(colsample_bytree=0.725,gamma=0.57,\n",
    "                             learning_rate=0.0083, max_depth=9,\n",
    "                             min_child_weight=0.96, n_estimators=1478,\n",
    "                             reg_alpha=0.38, reg_lambda=0.3,\n",
    "                             subsample=0.84, silent=1,\n",
    "                             random_state =8, nthread = 4)\n",
    "\n",
    "reg_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=54,\n",
    "                              learning_rate=0.02, n_estimators=820,\n",
    "                              max_bin = 455, bagging_fraction = 0.69,\n",
    "                              bagging_freq = 50, feature_fraction = 0.636,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =15, min_sum_hessian_in_leaf = 6)\n",
    "\n",
    "model1=reg_xgb.fit(df_train_all_new.drop([\"END_DATE\",\"TICKER_SYMBOL\",\"label\",\"coef\"],axis=1),\n",
    "                  df_train_all_new[\"label\"])\n",
    "\n",
    "model2=reg_lgb.fit(df_train_all_new.drop([\"END_DATE\",\"TICKER_SYMBOL\",\"label\",\"coef\"],axis=1),\n",
    "                  df_train_all_new[\"label\"])\n",
    "\n",
    "pred_test1=model1.predict(df_test.drop([\"TICKER_SYMBOL\"],axis=1))\n",
    "pred_test2=model2.predict(df_test.drop([\"TICKER_SYMBOL\"],axis=1))\n",
    "pred_test=np.exp(pred_test1*0.6+pred_test2*0.4)\n",
    "df_test[\"prediction\"]=pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub=pd.read_csv(\"../data/FDDC_financial_submit_20180524.csv\",header=None)\n",
    "df_sub.index=df_sub[0].apply(lambda x: x.split('.')[0]).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.set_index(\"TICKER_SYMBOL\").loc[df_sub.index]\n",
    "assert np.sum(df_sub.index!=df_sub.index)==0\n",
    "\n",
    "df_sub[\"value\"]=df_test[\"prediction\"].apply(lambda x: np.round(x/1e6,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"../submit/submission_20180715_181356.csv\",header=False,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
