{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs=pd.read_excel('../data/[Add June July] FDDC_financial_data_20180711/[New] Financial Data_20180711/Balance Sheet.xls',sheet_name=[0,1,2,3],parse_dates=['END_DATE'])\n",
    "df_is=pd.read_excel('../data/[Add June July] FDDC_financial_data_20180711/[New] Financial Data_20180711/Income Statement.xls',sheet_name=[0,1,2,3],parse_dates=['END_DATE'])\n",
    "df_cf=pd.read_excel('../data/[Add June July] FDDC_financial_data_20180711/[New] Financial Data_20180711/Cashflow Statement.xls',sheet_name=[0,1,2,3],parse_dates=['END_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before concat the shapes are:(1593, 73) (1922, 74) (304, 85)\n",
      "After concat the shapes are:(213866, 153)\n",
      "\n",
      "Before concat the shapes are:(1657, 60) (1905, 59) (314, 68)\n",
      "After concat the shapes are:(212182, 89)\n",
      "\n",
      "Before concat the shapes are:(1566, 76) (1872, 71) (287, 76)\n",
      "After concat the shapes are:(211717, 90)\n"
     ]
    }
   ],
   "source": [
    "print('Before concat the shapes are:{} {} {}'.format(df_bs[1].shape,df_bs[2].shape,df_bs[3].shape))\n",
    "print('After concat the shapes are:{}\\n'.format(pd.concat(df_bs,axis=0).shape))\n",
    "\n",
    "print('Before concat the shapes are:{} {} {}'.format(df_is[1].shape,df_is[2].shape,df_is[3].shape))\n",
    "print('After concat the shapes are:{}\\n'.format(pd.concat(df_is,axis=0).shape))\n",
    "\n",
    "print('Before concat the shapes are:{} {} {}'.format(df_cf[1].shape,df_cf[2].shape,df_cf[3].shape))\n",
    "print('After concat the shapes are:{}'.format(pd.concat(df_cf,axis=0).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs=pd.concat(df_bs,axis=0)\n",
    "df_is=pd.concat(df_is,axis=0)\n",
    "df_cf=pd.concat(df_cf,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_bs=df_bs.sort_values('PUBLISH_DATE').groupby(\n",
    "    [df_bs['TICKER_SYMBOL'],df_bs['END_DATE']]).apply(lambda x: x.iloc[-1])\n",
    "\n",
    "df_group_is=df_is.sort_values('PUBLISH_DATE').groupby(\n",
    "    [df_is['TICKER_SYMBOL'],df_is['END_DATE']]).apply(lambda x: x.iloc[-1])\n",
    "\n",
    "df_group_cf=df_cf.sort_values('PUBLISH_DATE').groupby(\n",
    "    [df_cf['TICKER_SYMBOL'],df_cf['END_DATE']]).apply(lambda x: x.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map=pd.read_csv('../data/maket_value_type_map.csv').set_index(\"TICKER_SYMBOL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##给每只股票添加股票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103595/103595 [00:33<00:00, 3062.45it/s]\n",
      "100%|██████████| 112822/112822 [00:28<00:00, 3891.59it/s]\n",
      "100%|██████████| 112763/112763 [00:28<00:00, 3947.83it/s]\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for i in tqdm(df_group_bs[\"TICKER_SYMBOL\"]):\n",
    "    try:\n",
    "        temp.append(df_map.loc[i][\"TYPE_NAME_CN\"])\n",
    "    except:\n",
    "        temp.append(None)\n",
    "df_group_bs[\"type\"]=temp\n",
    "temp=[]\n",
    "for i in tqdm(df_group_is[\"TICKER_SYMBOL\"]):\n",
    "    try:\n",
    "        temp.append(df_map.loc[i][\"TYPE_NAME_CN\"])\n",
    "    except:\n",
    "        temp.append(None)\n",
    "df_group_is[\"type\"]=temp\n",
    "temp=[]\n",
    "for i in tqdm(df_group_cf[\"TICKER_SYMBOL\"]):\n",
    "    try:\n",
    "        temp.append(df_map.loc[i][\"TYPE_NAME_CN\"])\n",
    "    except:\n",
    "        temp.append(None)\n",
    "df_group_cf[\"type\"]=temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##对重要特征进行填充缺失值防止缺失值过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_bs[\"CB_BORR\"]=df_group_bs[\"CB_BORR\"].fillna(0)\n",
    "df_group_bs[\"R_D\"]=df_group_bs[\"R_D\"].fillna(0)\n",
    "df_group_bs[\"BOND_PAYABLE\"]=df_group_bs[\"BOND_PAYABLE\"].fillna(0)\n",
    "df_group_bs[\"GOODWILL\"]=df_group_bs[\"GOODWILL\"].fillna(0)\n",
    "df_group_bs[\"TRADING_FA\"]=df_group_bs[\"TRADING_FA\"].fillna(0)\n",
    "df_group_bs[\"CIP\"]=df_group_bs[\"CIP\"].fillna(0)\n",
    "df_group_bs[\"LT_RECEIV\"]=df_group_bs[\"LT_RECEIV\"].fillna(0)\n",
    "df_group_bs[\"INT_PAYABLE\"]=df_group_bs[\"INT_PAYABLE\"].fillna(0)\n",
    "df_group_bs[\"TAXES_PAYABLE\"]=df_group_bs[\"TAXES_PAYABLE\"].fillna(0)\n",
    "df_group_bs[\"LT_BORR\"]=df_group_bs[\"LT_BORR\"].fillna(0)\n",
    "df_group_bs[\"PREMIUM_RECEIV\"]=df_group_bs[\"PREMIUM_RECEIV\"].fillna(0)  ##应收保费\n",
    "df_group_bs[\"AR\"]=df_group_bs[\"AR\"].fillna(0)                          ##应收账款"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rate_bs=df_group_bs.isnull().sum()/len(df_group_bs)\n",
    "null_rate_is=df_group_is.isnull().sum()/len(df_group_is)\n",
    "null_rate_cf=df_group_cf.isnull().sum()/len(df_group_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_bs=df_group_bs.drop(null_rate_bs[null_rate_bs>0.80].index,axis=1)\n",
    "df_group_is=df_group_is.drop(null_rate_is[null_rate_is>0.80].index,axis=1)\n",
    "df_group_cf=df_group_cf.drop(null_rate_cf[null_rate_cf>0.80].index,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After drop high null_rate columns the shape of bs are:(103595, 67)\n",
      "\n",
      "After drop high null_rate columns the shape of is are:(112822, 37)\n",
      "\n",
      "After drop high null_rate columns the shape of cf are:(112763, 43)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('After drop high null_rate columns the shape of bs are:{}\\n'.format(df_group_bs.shape))\n",
    "print('After drop high null_rate columns the shape of is are:{}\\n'.format(df_group_is.shape))\n",
    "print('After drop high null_rate columns the shape of cf are:{}\\n'.format(df_group_cf.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3560 corporations with full sheets\n"
     ]
    }
   ],
   "source": [
    "###只选择三表都全的公司\n",
    "\n",
    "ticker_set=(set(df_bs[\"TICKER_SYMBOL\"].unique()) & set(df_is[\"TICKER_SYMBOL\"].unique())\n",
    "           ) & set(df_cf[\"TICKER_SYMBOL\"].unique())\n",
    "print(\"there are {} corporations with full sheets\".format(len(ticker_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df_each,time_list,TICKER_SYMBOL):\n",
    "    df_temp=pd.DataFrame()\n",
    "    for col in df_each.columns:\n",
    "        for i,time in enumerate(time_list):\n",
    "            try:\n",
    "                df_temp[col+'_'+str(i)]=[df_each.loc[time,col]]\n",
    "            except:\n",
    "                df_temp[col+'_'+str(i)]=[np.nan]\n",
    "    \n",
    "    df_temp.index=[(6-len(TICKER_SYMBOL))*'0'+TICKER_SYMBOL]\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 错位时间 DataAugmentation\n",
    "train_time0=['2006-06-30','2006-09-30','2006-12-31','2007-03-31','2007-06-30','2007-09-30','2007-12-31',\n",
    "             '2008-03-31','2008-06-30','2008-09-30','2008-12-31','2009-03-31']\n",
    "\n",
    "train_time1=['2007-06-30','2007-09-30','2007-12-31','2008-03-31','2008-06-30','2008-09-30','2008-12-31',\n",
    "             '2009-03-31','2009-06-30','2009-09-30','2009-12-31','2010-03-31']\n",
    "\n",
    "train_time2=['2008-06-30','2008-09-30','2008-12-31','2009-03-31','2009-06-30','2009-09-30','2009-12-31',\n",
    "             '2010-03-31','2010-06-30','2010-09-30','2010-12-31','2011-03-31']\n",
    "\n",
    "train_time3=['2009-06-30','2009-09-30','2009-12-31','2010-03-31','2010-06-30','2010-09-30','2010-12-31',\n",
    "             '2011-03-31','2011-06-30','2011-09-30','2011-12-31','2012-03-31']\n",
    "\n",
    "train_time4=['2010-06-30','2010-09-30','2010-12-31','2011-03-31','2011-06-30','2011-09-30','2011-12-31',\n",
    "             '2012-03-31','2012-06-30','2012-09-30','2012-12-31','2013-03-31']\n",
    "\n",
    "train_time5=['2011-06-30','2011-09-30','2011-12-31','2012-03-31','2012-06-30','2012-09-30','2012-12-31',\n",
    "             '2013-03-31','2013-06-30','2013-09-30','2013-12-31','2014-03-31']\n",
    "\n",
    "train_time6=['2012-06-30','2012-09-30','2012-12-31','2013-03-31','2013-06-30','2013-09-30','2013-12-31',\n",
    "             '2014-03-31','2014-06-30','2014-09-30','2014-12-31','2015-03-31']\n",
    "\n",
    "train_time7=['2013-06-30','2013-09-30','2013-12-31','2014-03-31','2014-06-30','2014-09-30','2014-12-31',\n",
    "             '2015-03-31','2015-06-30','2015-09-30','2015-12-31',\"2016-03-31\"]\n",
    "\n",
    "train_time8=['2014-06-30','2014-09-30','2014-12-31','2015-03-31','2015-06-30','2015-09-30','2015-12-31',\n",
    "             \"2016-03-31\",'2016-06-30',\"2016-09-30\",\"2016-12-31\",\"2017-03-31\"]\n",
    "\n",
    "test_time=['2015-06-30','2015-09-30','2015-12-31',\"2016-03-31\",'2016-06-30',\"2016-09-30\",\"2016-12-31\",\n",
    "              \"2017-03-31\",\"2017-06-30\",\"2017-09-30\",\"2017-12-31\",\"2018-03-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 39/3560 [17:56<26:59:58, 27.61s/it]"
     ]
    }
   ],
   "source": [
    "##初始化参数用于盛放数据\n",
    "print(\"extracting features! please be patient it will take some time.....\")\n",
    "all_test=[]\n",
    "train0=[]\n",
    "train1=[]\n",
    "train2=[]\n",
    "train3=[]\n",
    "train4=[]\n",
    "train5=[]\n",
    "train6=[]\n",
    "train7=[]\n",
    "train8=[]\n",
    "\n",
    "for ticker in tqdm(ticker_set):\n",
    "    df_ticker_bs=df_group_bs.loc[ticker,:].drop([\"PARTY_ID\",\"TICKER_SYMBOL\",\"EXCHANGE_CD\",'PUBLISH_DATE',\n",
    "                                     'END_DATE_REP','END_DATE','FISCAL_PERIOD','REPORT_TYPE',\n",
    "                                      \"MERGED_FLAG\",],axis=1)\n",
    "    df_ticker_is=df_group_is.loc[ticker,:].drop([\"PARTY_ID\",\"TICKER_SYMBOL\",\"EXCHANGE_CD\",'PUBLISH_DATE',\n",
    "                                     'END_DATE_REP','END_DATE','FISCAL_PERIOD','REPORT_TYPE',\n",
    "                                      \"MERGED_FLAG\",],axis=1)\n",
    "    df_ticker_cf=df_group_cf.loc[ticker,:].drop([\"PARTY_ID\",\"TICKER_SYMBOL\",\"EXCHANGE_CD\",'PUBLISH_DATE',\n",
    "                                     'END_DATE_REP','END_DATE','FISCAL_PERIOD','REPORT_TYPE',\n",
    "                                      \"MERGED_FLAG\",],axis=1)\n",
    "    \n",
    "    ###提取测试集特征\n",
    "    feature_bs=extract(df_ticker_bs,test_time,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,test_time,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,test_time,str(ticker))\n",
    "    all_test.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))\n",
    "    \n",
    "    ###提取2009年训练集特征\n",
    "    feature_bs=extract(df_ticker_bs,train_time0,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,train_time0,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,train_time0,str(ticker))\n",
    "    train0.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))\n",
    "    \n",
    "    ###提取2010年训练集特征\n",
    "    feature_bs=extract(df_ticker_bs,train_time1,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,train_time1,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,train_time1,str(ticker))\n",
    "    train1.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))\n",
    "    \n",
    "    ###提取2011年训练集特征\n",
    "    feature_bs=extract(df_ticker_bs,train_time2,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,train_time2,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,train_time2,str(ticker))\n",
    "    train2.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))\n",
    "    \n",
    "    ###提取2012年训练集特征\n",
    "    feature_bs=extract(df_ticker_bs,train_time3,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,train_time3,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,train_time3,str(ticker))\n",
    "    train3.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))\n",
    "    \n",
    "    ###提取2013年训练集特征\n",
    "    feature_bs=extract(df_ticker_bs,train_time4,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,train_time4,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,train_time4,str(ticker))\n",
    "    train4.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))\n",
    "    \n",
    "    ###提取2014年训练集特征\n",
    "    feature_bs=extract(df_ticker_bs,train_time5,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,train_time5,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,train_time5,str(ticker))\n",
    "    train5.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))\n",
    "    \n",
    "    ###提取2015年训练集特征\n",
    "    feature_bs=extract(df_ticker_bs,train_time6,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,train_time6,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,train_time6,str(ticker))\n",
    "    train6.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))\n",
    "    \n",
    "    ###提取2016年训练集特征\n",
    "    feature_bs=extract(df_ticker_bs,train_time7,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,train_time7,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,train_time7,str(ticker))\n",
    "    train7.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))\n",
    "    \n",
    "    ###提取2017年训练集特征\n",
    "    feature_bs=extract(df_ticker_bs,train_time8,str(ticker))\n",
    "    feature_is=extract(df_ticker_is,train_time8,str(ticker))\n",
    "    feature_cf=extract(df_ticker_cf,train_time8,str(ticker))\n",
    "    train8.append(pd.concat([feature_bs,feature_is,feature_cf],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumbit=pd.read_csv('../data/FDDC_financial_submit_20180524.csv',header=None)\n",
    "\n",
    "### 提取需要预测的股票代码\n",
    "sumbit.index=sumbit[0].apply(lambda x: x.split('.')[0])\n",
    "###抽取需要预测的列\n",
    "X_test=pd.concat(all_test,axis=0)\n",
    "intersection=set(sumbit.index) & set(X_test.index)\n",
    "X_test=X_test.loc[intersection]\n",
    "X_test.to_csv('../data/test_data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0=pd.concat(train0,axis=0)\n",
    "X_train1=pd.concat(train1,axis=0)\n",
    "X_train2=pd.concat(train2,axis=0)\n",
    "X_train3=pd.concat(train3,axis=0)\n",
    "X_train4=pd.concat(train4,axis=0)\n",
    "X_train5=pd.concat(train5,axis=0)\n",
    "X_train6=pd.concat(train6,axis=0)\n",
    "X_train7=pd.concat(train7,axis=0)\n",
    "X_train8=pd.concat(train8,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "###提取Label\n",
    "y_train0=df_group_is[df_group_is[\"END_DATE\"]=='2009-06-30 00:00:00'][\"REVENUE\"]\n",
    "y_train0=y_train0.reset_index().drop('END_DATE',axis=1).set_index('TICKER_SYMBOL')\n",
    "\n",
    "##更改index\n",
    "new_index=[]\n",
    "for index in y_train0.index:\n",
    "    new_index.append((6-len(str(index)))*'0'+str(index))\n",
    "y_train0.index=new_index\n",
    "\n",
    "##只提取带Label的样本\n",
    "df_train0=pd.concat([X_train0,y_train0],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "###提取Label\n",
    "y_train1=df_group_is[df_group_is[\"END_DATE\"]=='2010-06-30 00:00:00'][\"REVENUE\"]\n",
    "y_train1=y_train1.reset_index().drop('END_DATE',axis=1).set_index('TICKER_SYMBOL')\n",
    "\n",
    "##更改index\n",
    "new_index=[]\n",
    "for index in y_train1.index:\n",
    "    new_index.append((6-len(str(index)))*'0'+str(index))\n",
    "y_train1.index=new_index\n",
    "\n",
    "##只提取带Label的样本\n",
    "df_train1=pd.concat([X_train1,y_train1],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "###提取Label\n",
    "y_train2=df_group_is[df_group_is[\"END_DATE\"]=='2011-06-30 00:00:00'][\"REVENUE\"]\n",
    "y_train2=y_train2.reset_index().drop('END_DATE',axis=1).set_index('TICKER_SYMBOL')\n",
    "\n",
    "##更改index\n",
    "new_index=[]\n",
    "for index in y_train2.index:\n",
    "    new_index.append((6-len(str(index)))*'0'+str(index))\n",
    "y_train2.index=new_index\n",
    "\n",
    "##只提取带Label的样本\n",
    "df_train2=pd.concat([X_train2,y_train2],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "###提取Label\n",
    "y_train3=df_group_is[df_group_is[\"END_DATE\"]=='2012-06-30 00:00:00'][\"REVENUE\"]\n",
    "y_train3=y_train3.reset_index().drop('END_DATE',axis=1).set_index('TICKER_SYMBOL')\n",
    "\n",
    "##更改index\n",
    "new_index=[]\n",
    "for index in y_train3.index:\n",
    "    new_index.append((6-len(str(index)))*'0'+str(index))\n",
    "y_train3.index=new_index\n",
    "\n",
    "##只提取带Label的样本\n",
    "df_train3=pd.concat([X_train3,y_train3],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "###提取Label\n",
    "y_train4=df_group_is[df_group_is[\"END_DATE\"]=='2013-06-30 00:00:00'][\"REVENUE\"]\n",
    "y_train4=y_train4.reset_index().drop('END_DATE',axis=1).set_index('TICKER_SYMBOL')\n",
    "\n",
    "##更改index\n",
    "new_index=[]\n",
    "for index in y_train4.index:\n",
    "    new_index.append((6-len(str(index)))*'0'+str(index))\n",
    "y_train4.index=new_index\n",
    "\n",
    "##只提取带Label的样本\n",
    "df_train4=pd.concat([X_train4,y_train4],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "###提取Label\n",
    "y_train5=df_group_is[df_group_is[\"END_DATE\"]=='2014-06-30 00:00:00'][\"REVENUE\"]\n",
    "y_train5=y_train5.reset_index().drop('END_DATE',axis=1).set_index('TICKER_SYMBOL')\n",
    "\n",
    "##更改index\n",
    "new_index=[]\n",
    "for index in y_train5.index:\n",
    "    new_index.append((6-len(str(index)))*'0'+str(index))\n",
    "y_train5.index=new_index\n",
    "\n",
    "##只提取带Label的样本\n",
    "df_train5=pd.concat([X_train5,y_train5],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "###提取Label\n",
    "y_train6=df_group_is[df_group_is[\"END_DATE\"]=='2015-06-30 00:00:00'][\"REVENUE\"]\n",
    "y_train6=y_train6.reset_index().drop('END_DATE',axis=1).set_index('TICKER_SYMBOL')\n",
    "\n",
    "##更改index\n",
    "new_index=[]\n",
    "for index in y_train6.index:\n",
    "    new_index.append((6-len(str(index)))*'0'+str(index))\n",
    "y_train6.index=new_index\n",
    "\n",
    "##只提取带Label的样本\n",
    "df_train6=pd.concat([X_train6,y_train6],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "###提取Label\n",
    "y_train7=df_group_is[df_group_is[\"END_DATE\"]=='2016-06-30 00:00:00'][\"REVENUE\"]\n",
    "y_train7=y_train7.reset_index().drop('END_DATE',axis=1).set_index('TICKER_SYMBOL')\n",
    "\n",
    "##更改index\n",
    "new_index=[]\n",
    "for index in y_train7.index:\n",
    "    new_index.append((6-len(str(index)))*'0'+str(index))\n",
    "y_train7.index=new_index\n",
    "\n",
    "##只提取带Label的样本\n",
    "df_train7=pd.concat([X_train7,y_train7],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "###提取Label\n",
    "y_train8=df_group_is[df_group_is[\"END_DATE\"]=='2017-06-30 00:00:00'][\"REVENUE\"]\n",
    "y_train8=y_train8.reset_index().drop('END_DATE',axis=1).set_index('TICKER_SYMBOL')\n",
    "\n",
    "##更改index\n",
    "new_index=[]\n",
    "for index in y_train8.index:\n",
    "    new_index.append((6-len(str(index)))*'0'+str(index))\n",
    "y_train8.index=new_index\n",
    "\n",
    "##只提取带Label的样本\n",
    "df_train8=pd.concat([X_train8,y_train8],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train0.to_csv('../data/df_train2009_all.csv')\n",
    "df_train1.to_csv('../data/df_train2010_all.csv')\n",
    "df_train2.to_csv('../data/df_train2011_all.csv')\n",
    "df_train3.to_csv('../data/df_train2012_all.csv')\n",
    "df_train4.to_csv('../data/df_train2013_all.csv')\n",
    "df_train5.to_csv('../data/df_train2014_all.csv')\n",
    "df_train6.to_csv('../data/df_train2015_all.csv')\n",
    "df_train7.to_csv('../data/df_train2016_all.csv')\n",
    "df_train8.to_csv('../data/df_train2017_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
